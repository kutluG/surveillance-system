"""
RAG Service: handles /analysis endpoint to produce semantic alerts.
"""
from typing import List, Optional
from fastapi import FastAPI, HTTPException, Request
from pydantic import BaseModel

from shared.logging_config import configure_logging, get_logger, log_context
from shared.audit_middleware import add_audit_middleware
from shared.metrics import instrument_app
from shared.models import Alert, SeverityLevel
from shared.middleware import add_rate_limiting

from .weaviate_client import semantic_search
from llm_client import generate_alert

# Configure logging first
logger = configure_logging("rag_service")

app = FastAPI(
    title="RAG Service",
    openapi_prefix="/api/v1"
)

# Add audit middleware
add_audit_middleware(app, service_name="rag_service")
instrument_app(app, service_name="rag_service")

# Add rate limiting middleware
add_rate_limiting(app, service_name="rag_service")


class AnalysisRequest(BaseModel):
    query: str
    context_ids: Optional[List[str]] = None


@app.post("/api/v1/analysis", response_model=Alert)
async def analyze(req: AnalysisRequest):
    """
    Analyze a natural language query against camera events, return an Alert.
    """
    with log_context(action="rag_analysis", query=req.query[:100]):  # Truncate query for logging
        logger.info("Analysis request received", extra={
            'action': 'rag_analysis',
            'query': req.query[:100],  # Truncate for logging
            'context_ids': req.context_ids
        })
        
        # Step 1: Retrieve context from Weaviate
        try:
            contexts = semantic_search(req.query, limit=5)
            logger.info("Context retrieved from Weaviate", extra={
                'action': 'weaviate_search',
                'context_count': len(contexts)
            })
        except Exception as e:
            logger.error("Weaviate search failed", extra={
                'action': 'weaviate_search_error',
                'error': str(e)
            })
            raise HTTPException(status_code=500, detail="Context retrieval error")
        
        # Step 2: Call LLM to generate alert JSON
        try:
            alert_json = generate_alert(req.query, contexts)
            logger.info("Alert generated by LLM", extra={
                'action': 'llm_generation',
                'severity': alert_json.get('severity', 'unknown')
            })
        except Exception as e:
            logger.error("LLM generation failed", extra={
                'action': 'llm_generation_error',
                'error': str(e)
            })
            raise HTTPException(status_code=500, detail="Alert generation error")
        
        # Step 3: Validate and build Alert model
        try:
            alert = Alert(
                alert_text=alert_json["alert_text"],
                severity=SeverityLevel(alert_json["severity"]),
                evidence_ids=alert_json["evidence_ids"],
            )
            logger.info("Alert model validated successfully", extra={
                'action': 'alert_validation',
                'severity': alert.severity.value,
                'evidence_count': len(alert.evidence_ids)
            })
            return alert
        except Exception as e:
            logger.error("Alert model validation failed", extra={
                'action': 'alert_validation_error',
                'error': str(e),
                'payload': str(alert_json)[:500]  # Truncate payload
            })
            raise HTTPException(status_code=500, detail="Alert validation error")

@app.get("/health")
async def health():
    logger.info("Health check performed", extra={'action': 'health_check'})
    return {"status": "ok"}